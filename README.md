# GPT-from-scratch

I initiated this repository with the purpose of coding the Generative Pre-trained Transformer (GPT) model entirely from scratch. This endeavor was sparked by my inspiration drawn from a captivating YouTube video presented by Dr. Andrej Karpathy. In the video, Dr. Karpathy, a prominent figure in the field of artificial intelligence, provided valuable insights and methodologies for understanding and implementing the GPT model. Motivated by the desire to delve deeper into the intricacies of the architecture and training process, I embarked on this coding journey to gain a hands-on understanding of the inner workings of GPT.

The repository serves as a practical exploration and learning platform, aiming to break down the complexities of GPT into comprehensible components. By coding the model from scratch, I aim to not only deepen my understanding but also provide a resource for others who share an interest in comprehending the nuances of transformer-based models. This project reflects a commitment to learning through practical implementation, aligning with the philosophy of open knowledge sharing within the AI and machine learning community.

Here's the link: https://www.youtube.com/watch?v=kCc8FmEb1nY
